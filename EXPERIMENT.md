### 天池新品实验室 — 淘宝直播商品识别
#### 参赛选手：艾宏峰，罗文斌，李智敏（名字不分先后）

[比赛链接](https://tianchi.aliyun.com/competition/entrance/231772/introduction)

#### 官方解释的注意事项：
1. 训练集与测试集的item_id不会出现重复现象，它是**唯一**的，而且**和文件名是对应的**。  
2. （暂定）推理运行时间需要保证在Nvidia P100 GPU 16G硬件环境下，单个直播切片的平均处理时间在**5s**。
3. 标注文件中的box左边是**0-based index**标注。  
4. A榜预计3月初启动测评，初赛将采用[docker](https://tianchi.aliyun.com/competition/entrance/231759/tab/174)镜像提交方式。官方baseline分数标准预计推迟到3月10日公布。
5. 队伍合并截止日期：3月21日中午12点。
6. ’古风‘与’古装‘合为’古风‘。

#### 论坛选手讨论观点：
1. @189***9607: 比赛主体跟重识别类似，把商品库图片当作一个被搜索的库（Gallery），从视频抽取图片然后在图片库中搜索相似的图。
2. @陈崇泰：git上有双向检索的代码。
**** 
### 数据EDA：
**图像库层面：**
1. 见[图3](IMG/3.png)，商品图像库**类别不平衡**。大部分商品图像库文件夹中含有5/6张图片，而且，**至少为2张图片**。  
2. 图像库图片总数200323张（**约20万张**）。
3. 见[图5](IMG/5.png)，商品库中单张图像所对应的标注文件里至少都有1个标注（即**没有局部图**）。  
4. 只有1张出现'display=2'(即侧面视角)的图片，为错标注数据（dispaly错标数据位置: ``data/train_dataset_part3/image_annotation/001541/0.json``）。**大部分都是试穿展示，然后再是纯商品展示**。**大部分图片为正面**，其次是背面，最后是侧面。  
5. **商品库图片都有文本描述**，大部分文本描述长度在**35个字左右**。  

**视频库层面：**
1. 见[图4](IMG/4.png)，商品图像库**类别不平衡**。视频库切片总数**30万张**。  
2. 所有mp4视频下，都保证有10个视频切片帧数（即单个视频都有10个frame）。  
3. 大部分单个视频切片下有1/2个标注（即1/2个bboxes），但也有’没有标注‘的或者’很多标注‘的情况。  
4. 大部分视频切片下的图属于**试穿展示图**和**正面视角图**。    
5. 单个视频只有一个视频标注，即单个视频中的10个视频切片都共享一个文本。**所有视频不一定有文本描述**。   
7. 大部分文本描述长度在**100个字左右**，比图像库的文本描述长。  

**其它:**
1. **视频库和图片库中出现的衣服不一定都能相互匹配到**。  
2. **图像库（24类）比视频库（23类）中多了‘古风’类别**。  
3. ‘instance_id’的命名规则：**2 + < item_id > + <选择>**。若某商品有两种选择（颜色，logo，套装等），一条裤子，一件衣服，则对于可以标号上述‘<选择>’为‘01’和‘02’。  
4. 商品图像文件夹正常情况下都是展示统一件商品，如果存在两个标注，有可能是如下[图1](IMG/1.png)所示：
- （1）**无关搭配**：存在无法被匹配的商品，即有‘instance_id’=0的商品。
- （2）**不同颜色或单件重复**：本质上都是统一件商品。
- （3）**套装搭配**：符合上面第3点提到的情况，是一个套装，‘instance_id’不一样，但相似。  
5. **在单个视频（即video-level）下，只存在展示一种商品，但中间可能会有不相干的商品，不过不相干商品都无法匹配到商品库**，因为其instance_id=0。而有时也会出现同一个视频中出现套装搭配（例如裤子和衣服）。如[图2](IMG/2.png)所示。
6. 在单个视频切片下（即frame_level）下，跟上面是一样的情况。
**** 
### 2020年3月2日
1. 根据前期EDA，对数据有以下看法：  
- 目标检测后留意**类别不平衡**对模型的影响。  
- 文本数据暂时不考虑加入模型中。  
- 总体数据质量还是不错的，因为大部分是’试穿’且‘正面’展示。  
- 当准备检索模型的训练集时，记得排除掉所有无法相互匹配到的商品（与论文做法一致）。  
- 视频库图片30万张还是太多了，后期如果训练检索模型，可以考虑‘一个视频只保留一个切片’的做法看看（参考历史文献中去除重复或相似图片的数据清理操作）。  
2. 根据历史文献的阅读，对模型有以下看法:  
- 先基于detectron2上复现Match R-CNN，后续再进行补充改进。  
